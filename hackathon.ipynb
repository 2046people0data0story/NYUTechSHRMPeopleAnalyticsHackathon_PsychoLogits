{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import xgboost\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pandas.read_csv('MEDIAN&MEAN_training.csv')\n",
    "dataset1 = data1.values\n",
    "\n",
    "data2 = pandas.read_csv('MEDIAN_imputed_training.csv')\n",
    "dataset2 = data2.values\n",
    "\n",
    "data3 = pandas.read_csv('KNN_imputed_training.csv')\n",
    "dataset3 = data3.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 5. 1. ... 3. 3. 3.]\n",
      " [6. 5. 1. ... 3. 3. 2.]\n",
      " [6. 3. 1. ... 5. 3. 2.]\n",
      " ...\n",
      " [8. 4. 0. ... 5. 5. 4.]\n",
      " [8. 1. 1. ... 4. 4. 4.]\n",
      " [8. 1. 1. ... 1. 2. 5.]]\n",
      "[[1 1 1 ... 3 3 3]\n",
      " [1 1 1 ... 3 3 2]\n",
      " [1 1 1 ... 5 3 2]\n",
      " ...\n",
      " [2 8 1 ... 5 5 1]\n",
      " [2 8 1 ... 3 4 2]\n",
      " [2 8 1 ... 5 3 3]]\n",
      "[[1 5 1 ... 3 3 3]\n",
      " [1 5 1 ... 3 3 2]\n",
      " [1 5 1 ... 5 3 2]\n",
      " ...\n",
      " [8 2 1 ... 5 5 1]\n",
      " [8 2 1 ... 3 4 2]\n",
      " [8 2 1 ... 5 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset1)\n",
    "print(dataset2)\n",
    "print(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "38\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print(len(data1.columns))\n",
    "print(len(data2.columns))\n",
    "print(len(data3.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = dataset1[:,0:37]\n",
    "Y1 = dataset1[:,37]\n",
    "\n",
    "X2 = dataset2[:,0:37]\n",
    "Y2 = dataset2[:,37]\n",
    "\n",
    "X3 = dataset3[:,0:37]\n",
    "Y3 = dataset3[:,37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder1 = LabelEncoder()\n",
    "label_encoder1 = label_encoder1.fit(Y1)\n",
    "label_encoded_y1 = label_encoder1.transform(Y1)\n",
    "seed = 8492\n",
    "test_size = 0.2\n",
    "X1_train, X1_test, y1_train, y1_test = model_selection.train_test_split(X1, label_encoded_y1, test_size=test_size, random_state=seed)\n",
    "\n",
    "label_encoder2 = LabelEncoder()\n",
    "label_encoder2 = label_encoder2.fit(Y2)\n",
    "label_encoded_y2 = label_encoder2.transform(Y2)\n",
    "seed = 8492\n",
    "test_size = 0.2\n",
    "X2_train, X2_test, y2_train, y2_test = model_selection.train_test_split(X2, label_encoded_y2, test_size=test_size, random_state=seed)\n",
    "\n",
    "label_encoder3 = LabelEncoder()\n",
    "label_encoder3 = label_encoder3.fit(Y3)\n",
    "label_encoded_y3 = label_encoder3.transform(Y3)\n",
    "seed = 8492\n",
    "test_size = 0.2\n",
    "X3_train, X3_test, y3_train, y3_test = model_selection.train_test_split(X3, label_encoded_y3, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
      "              validate_parameters=False, verbosity=None)\n",
      "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
      "              validate_parameters=False, verbosity=None)\n",
      "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
      "              validate_parameters=False, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "model1 = xgboost.XGBClassifier(scale_pos_weight=1)\n",
    "model1.fit(X1_train, y1_train)\n",
    "print(model1)\n",
    "\n",
    "model2 = xgboost.XGBClassifier(scale_pos_weight=1)\n",
    "model2.fit(X2_train, y2_train)\n",
    "print(model2)\n",
    "\n",
    "model3 = xgboost.XGBClassifier(scale_pos_weight=1)\n",
    "model3.fit(X3_train, y3_train)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(X1_test)\n",
    "predictions1 = [round(value) for value in y_pred1]\n",
    "\n",
    "y_pred2 = model2.predict(X2_test)\n",
    "predictions2 = [round(value) for value in y_pred2]\n",
    "\n",
    "y_pred3 = model3.predict(X3_test)\n",
    "predictions3 = [round(value) for value in y_pred3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.19%\n",
      "Accuracy: 60.93%\n",
      "Accuracy: 62.79%\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = accuracy_score(y1_test, predictions1)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy1 * 100.0))\n",
    "\n",
    "accuracy2 = accuracy_score(y2_test, predictions2)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy2 * 100.0))\n",
    "\n",
    "accuracy3 = accuracy_score(y3_test, predictions3)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy3 * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
